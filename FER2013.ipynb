{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER2013.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOPPtoTATN6b2JJspXi5Zhu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishabhs-s/Face-Recog-update/blob/master/FER2013.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRvIpjbG1oKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTMZNRWb1qQo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "2efe6b42-00fe-4ff1-e8ed-3219de1a690e"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r6YJXkb1iQH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "09b79242-34c4-4f9a-99f6-716e0ac51861"
      },
      "source": [
        "import sys, os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import np_utils\n",
        "\n",
        "#importing the data\n",
        "df=pd.read_csv(\"/content/drive/My Drive/fer2013/fer2013.csv\")\n",
        "\n",
        "'''\n",
        "emotions is divided into (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral) categories\n",
        "the pixels contains 48*48 coloums of data\n",
        "usage is basically the use of the data as training, public test or private test\n",
        "'''\n",
        "#declaring the test and train variables here we declare empty list for the variables\n",
        "X_train,train_y,X_test,test_y=[],[],[],[]\n",
        "\n",
        "'''\n",
        "As the pixel coloumn contains 48 values so we have convert into list\n",
        "We to it by iterating it through a for loop\n",
        "'''\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    val=row['pixels'].split(\" \")\n",
        "    try:\n",
        "        if 'Training' in row['Usage']:\n",
        "           X_train.append(np.array(val,'float32'))\n",
        "           train_y.append(row['emotion'])\n",
        "        elif 'PublicTest' in row['Usage']:\n",
        "           X_test.append(np.array(val,'float32'))\n",
        "           test_y.append(row['emotion'])\n",
        "    except:\n",
        "        print(f\"error occured at index :{index} and row:{row}\")\n",
        "\n",
        "#declaring variables\n",
        "\n",
        "num_features = 64 # no.of features of conv2d layer\n",
        "num_labels = 7\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "width, height = 48, 48 #pixel\n",
        "#As keras only accepts the np array format input so we have to convert all the train and test split into np array\n",
        "\n",
        "X_train = np.array(X_train,'float32')\n",
        "train_y = np.array(train_y,'float32')\n",
        "X_test = np.array(X_test,'float32')\n",
        "test_y = np.array(test_y,'float32')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#normalizing data between oand 1\n",
        "#Min max scaling\n",
        "#Xnorm=$\\frac{x-minvalue}{mavalue-minvalue}$\n",
        "#X_train -= np.mean(X_train, axis=0)\n",
        "#X_train /= np.std(X_train, axis=0)\n",
        "\n",
        "#X_test -= np.mean(X_test, axis=0)\n",
        "#X_test /= np.std(X_test, axis=0)\n",
        "\n",
        "#X_test=X_test/X_test.max()\n",
        "#X_train=X_train/X_train.max()\n",
        "X_train /= 255 #normalize inputs between [0, 1]\n",
        "X_test /= 255\n",
        "\n",
        "\n",
        "\n",
        "X_train=X_train.reshape(X_train.shape[0],width,height,1)\n",
        "X_test=X_test.reshape(X_test.shape[0],width,height,1)\n",
        "\n",
        " #converting to categoricals\n",
        "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
        "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)\n",
        "\n",
        "\n",
        "##designing the cnn\n",
        "#1st convolution layer\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(num_features,kernel_size=(5,5),activation=\"relu\",input_shape=(X_train.shape[1:])))#kernel size is the filter size that we are going to superimpose n images,relu is recifier activation function \n",
        "model.add(Conv2D(num_features,kernel_size=(5,5),activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(5,5),strides=(2,2))) # mqx pool function choosesthe max value from the pool and ouput is fomed with that\n",
        "model.add(Dropout(0.5)) #drop out somethings so that model doesnt overfit\n",
        "\n",
        "#2nd convolution layer\n",
        "model.add(Conv2D(num_features,kernel_size=(3,3),activation=\"relu\"))#kernel size is the filter size that we are going to superimpose n images,relu is recifier activation function \n",
        "model.add(Conv2D(num_features,kernel_size=(3,3),activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2))) # mqx pool function choosesthe max value from the pool and ouput is fomed with that\n",
        "model.add(Dropout(0.5)) #drop out somethings so that model doesnt overfit\n",
        "\n",
        "#3rd convolution layer-double filers\n",
        "model.add(Conv2D(2*num_features,kernel_size=(3,3),activation=\"relu\"))\n",
        "model.add(Conv2D(2*num_features,kernel_size=(3,3),activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "#fully connected neural networks\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(num_labels, activation='softmax')) # softmax as we have to choose bw the available labels given\n",
        "# model.summary()\n",
        "\n",
        "#Compliling the model\n",
        "model.compile(loss='categorical_crossentropy'\n",
        "    , optimizer=keras.optimizers.Adam()\n",
        "    , metrics=['accuracy'])\n",
        "\n",
        "#Training the model\n",
        "model.fit(X_train, train_y,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, test_y),\n",
        "          shuffle=True)\n",
        "\n",
        "\n",
        "score = model.evaluate(X_test, test_y)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', 100*score[1])\n",
        "\n",
        "#function for drawing bar chart for emotion preditions\n",
        "def emotion_analysis(emotions):\n",
        "    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
        "    y_pos = np.arange(len(objects))\n",
        "    \n",
        "    plt.bar(y_pos, emotions, align='center', alpha=0.5)\n",
        "    plt.xticks(y_pos, objects)\n",
        "    plt.ylabel('percentage')\n",
        "    plt.title('emotion')\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 28709 samples, validate on 3589 samples\n",
            "Epoch 1/50\n",
            "28709/28709 [==============================] - 28s 966us/step - loss: 1.8168 - accuracy: 0.2504 - val_loss: 1.8140 - val_accuracy: 0.2494\n",
            "Epoch 2/50\n",
            "28709/28709 [==============================] - 21s 723us/step - loss: 1.8124 - accuracy: 0.2513 - val_loss: 1.8145 - val_accuracy: 0.2494\n",
            "Epoch 3/50\n",
            "28709/28709 [==============================] - 21s 722us/step - loss: 1.8117 - accuracy: 0.2513 - val_loss: 1.8148 - val_accuracy: 0.2494\n",
            "Epoch 4/50\n",
            "28709/28709 [==============================] - 21s 723us/step - loss: 1.8118 - accuracy: 0.2513 - val_loss: 1.8117 - val_accuracy: 0.2494\n",
            "Epoch 5/50\n",
            "28709/28709 [==============================] - 21s 723us/step - loss: 1.8115 - accuracy: 0.2512 - val_loss: 1.8112 - val_accuracy: 0.2494\n",
            "Epoch 6/50\n",
            "28709/28709 [==============================] - 21s 719us/step - loss: 1.8112 - accuracy: 0.2513 - val_loss: 1.8117 - val_accuracy: 0.2494\n",
            "Epoch 7/50\n",
            "28709/28709 [==============================] - 21s 722us/step - loss: 1.8110 - accuracy: 0.2513 - val_loss: 1.8113 - val_accuracy: 0.2494\n",
            "Epoch 8/50\n",
            "28709/28709 [==============================] - 21s 722us/step - loss: 1.8106 - accuracy: 0.2513 - val_loss: 1.8117 - val_accuracy: 0.2494\n",
            "Epoch 9/50\n",
            "28709/28709 [==============================] - 21s 719us/step - loss: 1.8106 - accuracy: 0.2513 - val_loss: 1.8135 - val_accuracy: 0.2494\n",
            "Epoch 10/50\n",
            "28709/28709 [==============================] - 21s 721us/step - loss: 1.8107 - accuracy: 0.2513 - val_loss: 1.8121 - val_accuracy: 0.2494\n",
            "Epoch 11/50\n",
            "28709/28709 [==============================] - 21s 724us/step - loss: 1.8107 - accuracy: 0.2513 - val_loss: 1.8119 - val_accuracy: 0.2494\n",
            "Epoch 12/50\n",
            "28709/28709 [==============================] - 21s 720us/step - loss: 1.8109 - accuracy: 0.2513 - val_loss: 1.8114 - val_accuracy: 0.2494\n",
            "Epoch 13/50\n",
            "28709/28709 [==============================] - 21s 720us/step - loss: 1.8106 - accuracy: 0.2513 - val_loss: 1.8124 - val_accuracy: 0.2494\n",
            "Epoch 14/50\n",
            "28709/28709 [==============================] - 21s 739us/step - loss: 1.8106 - accuracy: 0.2513 - val_loss: 1.8125 - val_accuracy: 0.2494\n",
            "Epoch 15/50\n",
            "28709/28709 [==============================] - 21s 724us/step - loss: 1.8110 - accuracy: 0.2513 - val_loss: 1.8128 - val_accuracy: 0.2494\n",
            "Epoch 16/50\n",
            "28709/28709 [==============================] - 21s 720us/step - loss: 1.8108 - accuracy: 0.2513 - val_loss: 1.8109 - val_accuracy: 0.2494\n",
            "Epoch 17/50\n",
            "28709/28709 [==============================] - 21s 721us/step - loss: 1.8107 - accuracy: 0.2513 - val_loss: 1.8124 - val_accuracy: 0.2494\n",
            "Epoch 18/50\n",
            "28709/28709 [==============================] - 21s 720us/step - loss: 1.8105 - accuracy: 0.2513 - val_loss: 1.8114 - val_accuracy: 0.2494\n",
            "Epoch 19/50\n",
            "28709/28709 [==============================] - 21s 720us/step - loss: 1.8107 - accuracy: 0.2513 - val_loss: 1.8112 - val_accuracy: 0.2494\n",
            "Epoch 20/50\n",
            "28709/28709 [==============================] - 21s 720us/step - loss: 1.8107 - accuracy: 0.2513 - val_loss: 1.8121 - val_accuracy: 0.2494\n",
            "Epoch 21/50\n",
            "28709/28709 [==============================] - 21s 722us/step - loss: 1.8108 - accuracy: 0.2513 - val_loss: 1.8121 - val_accuracy: 0.2494\n",
            "Epoch 22/50\n",
            "28709/28709 [==============================] - 21s 721us/step - loss: 1.8108 - accuracy: 0.2513 - val_loss: 1.8121 - val_accuracy: 0.2494\n",
            "Epoch 23/50\n",
            "28709/28709 [==============================] - 21s 719us/step - loss: 1.8108 - accuracy: 0.2513 - val_loss: 1.8115 - val_accuracy: 0.2494\n",
            "Epoch 24/50\n",
            "28709/28709 [==============================] - 21s 720us/step - loss: 1.8105 - accuracy: 0.2513 - val_loss: 1.8121 - val_accuracy: 0.2494\n",
            "Epoch 25/50\n",
            "28709/28709 [==============================] - 21s 722us/step - loss: 1.8107 - accuracy: 0.2513 - val_loss: 1.8113 - val_accuracy: 0.2494\n",
            "Epoch 26/50\n",
            "28709/28709 [==============================] - 21s 720us/step - loss: 1.8108 - accuracy: 0.2513 - val_loss: 1.8109 - val_accuracy: 0.2494\n",
            "Epoch 27/50\n",
            "28709/28709 [==============================] - 21s 719us/step - loss: 1.8103 - accuracy: 0.2513 - val_loss: 1.8111 - val_accuracy: 0.2494\n",
            "Epoch 28/50\n",
            "28709/28709 [==============================] - 21s 720us/step - loss: 1.8104 - accuracy: 0.2513 - val_loss: 1.8116 - val_accuracy: 0.2494\n",
            "Epoch 29/50\n",
            "28709/28709 [==============================] - 21s 733us/step - loss: 1.8107 - accuracy: 0.2513 - val_loss: 1.8122 - val_accuracy: 0.2494\n",
            "Epoch 30/50\n",
            "28709/28709 [==============================] - 21s 720us/step - loss: 1.8106 - accuracy: 0.2513 - val_loss: 1.8111 - val_accuracy: 0.2494\n",
            "Epoch 31/50\n",
            "28709/28709 [==============================] - 21s 722us/step - loss: 1.8105 - accuracy: 0.2513 - val_loss: 1.8116 - val_accuracy: 0.2494\n",
            "Epoch 32/50\n",
            "28709/28709 [==============================] - 21s 719us/step - loss: 1.8105 - accuracy: 0.2513 - val_loss: 1.8124 - val_accuracy: 0.2494\n",
            "Epoch 33/50\n",
            "28709/28709 [==============================] - 21s 719us/step - loss: 1.8106 - accuracy: 0.2513 - val_loss: 1.8119 - val_accuracy: 0.2494\n",
            "Epoch 34/50\n",
            "17024/28709 [================>.............] - ETA: 8s - loss: 1.8099 - accuracy: 0.2500"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMxpIpTp3QYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('ferlatest.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ix3fhqd3NUl7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "128KUvZlOJCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fer_json = model.to_json()\n",
        "with open(\"ferlatest.json\", \"w\") as json_file:\n",
        "    json_file.write(fer_json)\n",
        "model.save_weights(\"ferlatest.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}