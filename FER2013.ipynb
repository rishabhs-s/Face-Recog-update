{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER2013.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPbzlz7XEG5bPf/W+KKODQy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishabhs-s/Face-Recog-update/blob/master/FER2013.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRvIpjbG1oKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTMZNRWb1qQo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "1dd2056c-e534-4955-f916-a13b6723d3e8"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r6YJXkb1iQH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 907
        },
        "outputId": "9b77feb1-3b27-4075-b143-6254c53668f5"
      },
      "source": [
        "import sys, os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import np_utils\n",
        "\n",
        "#importing the data\n",
        "df=pd.read_csv(\"/content/drive/My Drive/fer2013/fer2013.csv\")\n",
        "\n",
        "'''\n",
        "emotions is divided into (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral) categories\n",
        "the pixels contains 48*48 coloums of data\n",
        "usage is basically the use of the data as training, public test or private test\n",
        "'''\n",
        "#declaring the test and train variables here we declare empty list for the variables\n",
        "X_train,train_y,X_test,test_y=[],[],[],[]\n",
        "\n",
        "'''\n",
        "As the pixel coloumn contains 48 values so we have convert into list\n",
        "We to it by iterating it through a for loop\n",
        "'''\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    val=row['pixels'].split(\" \")\n",
        "    try:\n",
        "        if 'Training' in row['Usage']:\n",
        "           X_train.append(np.array(val,'float32'))\n",
        "           train_y.append(row['emotion'])\n",
        "        elif 'PublicTest' in row['Usage']:\n",
        "           X_test.append(np.array(val,'float32'))\n",
        "           test_y.append(row['emotion'])\n",
        "    except:\n",
        "        print(f\"error occured at index :{index} and row:{row}\")\n",
        "\n",
        "#declaring variables\n",
        "\n",
        "num_features = 64 # no.of features of conv2d layer\n",
        "num_labels = 7\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "width, height = 48, 48 #pixel\n",
        "#As keras only accepts the np array format input so we have to convert all the train and test split into np array\n",
        "\n",
        "X_train = np.array(X_train,'float32')\n",
        "train_y = np.array(train_y,'float32')\n",
        "X_test = np.array(X_test,'float32')\n",
        "test_y = np.array(test_y,'float32')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#normalizing data between oand 1\n",
        "#Min max scaling\n",
        "#Xnorm=$\\frac{x-minvalue}{mavalue-minvalue}$\n",
        "#X_train -= np.mean(X_train, axis=0)\n",
        "#X_train /= np.std(X_train, axis=0)\n",
        "\n",
        "#X_test -= np.mean(X_test, axis=0)\n",
        "#X_test /= np.std(X_test, axis=0)\n",
        "\n",
        "X_test=X_test/X_test.max()\n",
        "X_train=X_train/X_train.max()\n",
        "\n",
        "\n",
        "X_train=X_train.reshape(X_train.shape[0],width,height,1)\n",
        "X_test=X_test.reshape(X_test.shape[0],width,height,1)\n",
        "\n",
        " #converting to categoricals\n",
        "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
        "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)\n",
        "\n",
        "\n",
        "##designing the cnn\n",
        "#1st convolution layer\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(num_features,kernel_size=(3,3),activation=\"relu\",input_shape=(X_train.shape[1:])))#kernel size is the filter size that we are going to superimpose n images,relu is recifier activation function \n",
        "model.add(Conv2D(num_features,kernel_size=(3,3),activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2))) # mqx pool function choosesthe max value from the pool and ouput is fomed with that\n",
        "model.add(Dropout(0.5)) #drop out somethings so that model doesnt overfit\n",
        "\n",
        "#2nd convolution layer\n",
        "model.add(Conv2D(num_features,kernel_size=(3,3),activation=\"relu\"))#kernel size is the filter size that we are going to superimpose n images,relu is recifier activation function \n",
        "model.add(Conv2D(num_features,kernel_size=(3,3),activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2))) # mqx pool function choosesthe max value from the pool and ouput is fomed with that\n",
        "model.add(Dropout(0.5)) #drop out somethings so that model doesnt overfit\n",
        "\n",
        "#3rd convolution layer-double filers\n",
        "model.add(Conv2D(2*num_features,kernel_size=(3,3),activation=\"relu\"))\n",
        "model.add(Conv2D(2*num_features,kernel_size=(3,3),activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "#fully connected neural networks\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(num_labels, activation='softmax')) # softmax as we have to choose bw the available labels given\n",
        "# model.summary()\n",
        "\n",
        "#Compliling the model\n",
        "model.compile(loss='categorical_crossentropy'\n",
        "    , optimizer=keras.optimizers.Adam()\n",
        "    , metrics=['accuracy'])\n",
        "\n",
        "#Training the model\n",
        "model.fit(X_train, train_y,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, test_y),\n",
        "          shuffle=True)\n",
        "\n",
        "\n",
        "score = model.evaluate(X_test, test_y)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', 100*score[1])\n",
        "\n",
        "#function for drawing bar chart for emotion preditions\n",
        "def emotion_analysis(emotions):\n",
        "    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
        "    y_pos = np.arange(len(objects))\n",
        "    \n",
        "    plt.bar(y_pos, emotions, align='center', alpha=0.5)\n",
        "    plt.xticks(y_pos, objects)\n",
        "    plt.ylabel('percentage')\n",
        "    plt.title('emotion')\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 28709 samples, validate on 3589 samples\n",
            "Epoch 1/50\n",
            "28709/28709 [==============================] - 29s 1ms/step - loss: 1.8169 - accuracy: 0.2491 - val_loss: 1.8142 - val_accuracy: 0.2494\n",
            "Epoch 2/50\n",
            "28709/28709 [==============================] - 22s 771us/step - loss: 1.8126 - accuracy: 0.2513 - val_loss: 1.8154 - val_accuracy: 0.2494\n",
            "Epoch 3/50\n",
            "28709/28709 [==============================] - 22s 767us/step - loss: 1.8119 - accuracy: 0.2513 - val_loss: 1.8138 - val_accuracy: 0.2494\n",
            "Epoch 4/50\n",
            "28709/28709 [==============================] - 22s 769us/step - loss: 1.8112 - accuracy: 0.2513 - val_loss: 1.8121 - val_accuracy: 0.2494\n",
            "Epoch 5/50\n",
            "28709/28709 [==============================] - 22s 763us/step - loss: 1.8111 - accuracy: 0.2513 - val_loss: 1.8115 - val_accuracy: 0.2494\n",
            "Epoch 6/50\n",
            "28709/28709 [==============================] - 22s 767us/step - loss: 1.8113 - accuracy: 0.2513 - val_loss: 1.8118 - val_accuracy: 0.2494\n",
            "Epoch 7/50\n",
            "28709/28709 [==============================] - 22s 762us/step - loss: 1.8110 - accuracy: 0.2513 - val_loss: 1.8118 - val_accuracy: 0.2494\n",
            "Epoch 8/50\n",
            "28709/28709 [==============================] - 22s 763us/step - loss: 1.8109 - accuracy: 0.2513 - val_loss: 1.8114 - val_accuracy: 0.2494\n",
            "Epoch 9/50\n",
            "28709/28709 [==============================] - 22s 776us/step - loss: 1.8109 - accuracy: 0.2513 - val_loss: 1.8134 - val_accuracy: 0.2494\n",
            "Epoch 10/50\n",
            "28709/28709 [==============================] - 22s 771us/step - loss: 1.8107 - accuracy: 0.2513 - val_loss: 1.8110 - val_accuracy: 0.2494\n",
            "Epoch 11/50\n",
            "28709/28709 [==============================] - 22s 767us/step - loss: 1.8108 - accuracy: 0.2513 - val_loss: 1.8125 - val_accuracy: 0.2494\n",
            "Epoch 12/50\n",
            "28709/28709 [==============================] - 22s 764us/step - loss: 1.8108 - accuracy: 0.2513 - val_loss: 1.8108 - val_accuracy: 0.2494\n",
            "Epoch 13/50\n",
            "28709/28709 [==============================] - 22s 766us/step - loss: 1.8106 - accuracy: 0.2513 - val_loss: 1.8116 - val_accuracy: 0.2494\n",
            "Epoch 14/50\n",
            "28709/28709 [==============================] - 22s 768us/step - loss: 1.8106 - accuracy: 0.2513 - val_loss: 1.8142 - val_accuracy: 0.2494\n",
            "Epoch 15/50\n",
            "28709/28709 [==============================] - 22s 765us/step - loss: 1.8107 - accuracy: 0.2513 - val_loss: 1.8113 - val_accuracy: 0.2494\n",
            "Epoch 16/50\n",
            "28709/28709 [==============================] - 22s 770us/step - loss: 1.8106 - accuracy: 0.2513 - val_loss: 1.8110 - val_accuracy: 0.2494\n",
            "Epoch 17/50\n",
            "28709/28709 [==============================] - 22s 765us/step - loss: 1.8106 - accuracy: 0.2513 - val_loss: 1.8110 - val_accuracy: 0.2494\n",
            "Epoch 18/50\n",
            "28709/28709 [==============================] - 22s 766us/step - loss: 1.8106 - accuracy: 0.2513 - val_loss: 1.8122 - val_accuracy: 0.2494\n",
            "Epoch 19/50\n",
            "28709/28709 [==============================] - 22s 766us/step - loss: 1.8105 - accuracy: 0.2513 - val_loss: 1.8109 - val_accuracy: 0.2494\n",
            "Epoch 20/50\n",
            "28709/28709 [==============================] - 22s 760us/step - loss: 1.8102 - accuracy: 0.2513 - val_loss: 1.8116 - val_accuracy: 0.2494\n",
            "Epoch 21/50\n",
            "28709/28709 [==============================] - 22s 761us/step - loss: 1.8104 - accuracy: 0.2513 - val_loss: 1.8134 - val_accuracy: 0.2494\n",
            "Epoch 22/50\n",
            "28709/28709 [==============================] - 22s 765us/step - loss: 1.8108 - accuracy: 0.2513 - val_loss: 1.8132 - val_accuracy: 0.2494\n",
            "Epoch 23/50\n",
            "28709/28709 [==============================] - 22s 773us/step - loss: 1.8107 - accuracy: 0.2513 - val_loss: 1.8124 - val_accuracy: 0.2494\n",
            "Epoch 24/50\n",
            "28709/28709 [==============================] - 22s 773us/step - loss: 1.8105 - accuracy: 0.2513 - val_loss: 1.8126 - val_accuracy: 0.2494\n",
            "Epoch 25/50\n",
            "28709/28709 [==============================] - 22s 762us/step - loss: 1.8102 - accuracy: 0.2513 - val_loss: 1.8117 - val_accuracy: 0.2494\n",
            "Epoch 26/50\n",
            "20992/28709 [====================>.........] - ETA: 5s - loss: 1.8103 - accuracy: 0.2505"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMxpIpTp3QYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}